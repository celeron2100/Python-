{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "請在此輸入要迭代的次數 : 5\n",
      "Booking_com_train_訓練Word2Vec語料.txt file1 converted,OK!!\n",
      "Traning model is complete!!\n",
      "\n",
      "\n",
      "迭代第  1  次 未使用Word2Vec擴大的 Accuracy =  78.0 %\n",
      "迭代第  1  次  有使用Word2Vec擴大的 Accuracy =  78.0 %\n",
      "\n",
      "迭代第  2  次 未使用Word2Vec擴大的 Accuracy =  78.0 %\n",
      "迭代第  2  次  有使用Word2Vec擴大的 Accuracy =  78.0 %\n",
      "\n",
      "迭代第  3  次 未使用Word2Vec擴大的 Accuracy =  78.0 %\n",
      "迭代第  3  次  有使用Word2Vec擴大的 Accuracy =  78.0 %\n",
      "\n",
      "迭代第  4  次 未使用Word2Vec擴大的 Accuracy =  78.0 %\n",
      "迭代第  4  次  有使用Word2Vec擴大的 Accuracy =  78.0 %\n",
      "\n",
      "迭代第  5  次 未使用Word2Vec擴大的 Accuracy =  78.0 %\n",
      "迭代第  5  次  有使用Word2Vec擴大的 Accuracy =  78.0 %\n",
      "\n",
      "未使用Word2Vec擴大的平均 Accuracy = 78.0 %\n",
      "有使用Word2Vec擴大的平均 Accuracy = 78.0 %\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import os\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from string import punctuation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import libsvm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "C = 10  #懲罰常數\n",
    "component = 800  #降維維度\n",
    "most_simlr = 2  #擴展詞彙\n",
    "max_fea = 1300 #特徵數量\n",
    "vectorizer_count = CountVectorizer(analyzer='word',stop_words='english', encoding='utf-8',lowercase=True,max_features=max_fea)\n",
    "svd = TruncatedSVD(n_components=component)\n",
    "\n",
    "average_accuracy = 0\n",
    "word2vec_average_accuracy = 0\n",
    "\n",
    "#counter = int(input(\"請在此輸入要迭代的次數 : \"))\n",
    "counter = 5\n",
    "def Accuracy_set_value(hit,miss):\n",
    "    Accuracy = hit/(hit+miss)\n",
    "    return Accuracy\n",
    "#分析的評論句子用的前處理函數，會對輸入的句子去除標點符號，數字，非ascii字符，文字詞幹，轉換為寫小字母。\n",
    "def sentence_preprocess(sentence):\n",
    "    global punctuation\n",
    "    punctuation += \",\"+\"'\"+\".\"+\"&\"+\"!\"+\";\"+\":\"+\"...\"+\"´\"+\",\"\n",
    "    ascii_list = string.ascii_letters+\" \"\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    sentence = sentence.lower()\n",
    "    sentence = list(sentence)\n",
    "    out_sentence = \"\".join(stemmer.stem(c) for c in sentence if c not in punctuation)\n",
    "    out_sentence= \"\".join([i for i in out_sentence if not i.isdigit()])\n",
    "    out_sentence= \"\".join([i for i in out_sentence if i in ascii_list])\n",
    "    out_sentence = \" \".join(out_sentence.split())\n",
    "    out_sentence2 = [stemmer.stem(plural) for plural in out_sentence.split()]\n",
    "    out_sentence2 = \" \".join(out_sentence2)\n",
    "    if out_sentence2 == \"\":\n",
    "        out_sentence2 = \" The quick brown fox jumps over the lazy dog\"\n",
    "    out_sentence2 = out_sentence2.split()\n",
    "    return out_sentence2  #回傳值是List型態\n",
    "#Word2Vec使用的訓練語料庫必須為文字句子陣列，不須去詞幹，不須轉換大小寫。\n",
    "def word2vec_train():\n",
    "    global Word2Vec_Hotel_Traning_Model\n",
    "    training_list = []\n",
    "    with codecs.open(\"Booking_com_train_訓練Word2Vec語料.txt\",encoding=\"utf-8\", errors=\"backslashreplace\") as sourceFile1:         \n",
    "        training_file1 = sourceFile1.readlines()\n",
    "        for document_1 in training_file1:\n",
    "            training_list.append(document_1.split(\" \"))\n",
    "        print(\"Booking_com_train_訓練Word2Vec語料.txt file1 converted,OK!!\")\n",
    "    Word2Vec_Hotel_Traning_Model = Word2Vec(training_list)\n",
    "    print(\"Traning model is complete!!\")\n",
    "    print()\n",
    "word2vec_train()\n",
    "#接收的是一個句子的List  例如 [then,you,can,debug,the,threshold,with,generated ,tsv]\n",
    "#用於把原本的句子按照Word2Vec相關性擴展成更大的句子清單\n",
    "#基本上，一個原本有10個單字的句子，會被擴展成210個單字的句子\n",
    "#擴展過後的200個單字會加進原本10個單字句子的後面。\n",
    "#擴展的規則是，不去除重複的詞彙。\n",
    "def word2vec_extend(sentence_word_list):\n",
    "    if  type(sentence_word_list) == str:\n",
    "        sentence_word_list = sentence_word_list.split()\n",
    "    temp_list = []  #用於暫時存放擴展回傳的List\n",
    "    for word_text in sentence_word_list:\n",
    "        to_extend_word_list = Word2Vec_Hotel_Traning_Model.most_similar(word_text, topn=most_simlr)\n",
    "        temp_sentence = \"\"\n",
    "        for i in range(len(to_extend_word_list)):\n",
    "            temp_sentence += to_extend_word_list[i][0]+\" \"\n",
    "        temp_sentence = temp_sentence.split()\n",
    "        temp_list += temp_sentence\n",
    "    sentence_word_list += temp_list\n",
    "    return sentence_word_list   #把擴展後的110單字句子List回傳\n",
    "for Routine in range(counter):\n",
    "    Routine +=1\n",
    "    #實驗一 原本的評論語句不使用Word2Vec擴展\n",
    "    #步驟0.讀入Train資料集 400筆\n",
    "    Train_Booking_review = pd.read_csv(\"Booking_com_train_400筆.csv\",sep=',',names=[\"Polarity\",\"Context\"])\n",
    "    Train_Booking_review_Context = Train_Booking_review.Context\n",
    "    Train_Booking_review_Polarity = Train_Booking_review.Polarity\n",
    "    train_data_df_list = Train_Booking_review_Context.fillna(method=\"ffill\")\n",
    "    #步驟1.Train資料集 400筆 使用CountVectorizer 轉換為Bag of Word\n",
    "    Train_corpus_data_features_count = vectorizer_count.fit_transform(train_data_df_list)\n",
    "    Train_corpus_data_features_count_nd = Train_corpus_data_features_count.toarray()\n",
    "    #Train_corpus_data_features_count_nd.shape\n",
    "    #步驟2.提取出Train的Feature Word特徵詞串列List\n",
    "    #Train_feature_list = vectorizer_count.get_feature_names()\n",
    "    #print(Train_feature_list)\n",
    "    #步驟3.讀入test資料集 100筆\n",
    "    Test_Booking_review = pd.read_csv(\"Booking_com_test_100筆.csv\",sep=',',names=[\"Polarity\",\"Context\"])\n",
    "    Test_Booking_review_Context = Test_Booking_review.Context\n",
    "    Test_Booking_review_Polarity = Test_Booking_review.Polarity\n",
    "    Test_data_df_list = Test_Booking_review_Context.fillna(method=\"ffill\")\n",
    "    #print(Test_data_df_list)\n",
    "    #步驟4.把test的資料集中的每一筆評論依序提取出來\n",
    "    #步驟5.使用迭代的方式比對每一筆評論中的單字是否存在於Feature Word特徵詞串列List中\n",
    "    #步驟6.以一則評論一個串列產生出Test的特徵詞串列-矩陣\n",
    "    Test_corpus_data_features_count = vectorizer_count.transform(Test_data_df_list)\n",
    "    Test_corpus_data_features_count_nd = Test_corpus_data_features_count.toarray()\n",
    "    #Test_corpus_data_features_count_nd.shape\n",
    "    #步驟7.把Train 與 Test 矩陣合併 意即 Train矩陣 後面串接 Test矩陣\n",
    "    #合併後的矩陣命名為 「Combined_Matrix_01」\n",
    "    #============去除SVD============#Combined_Matrix_01 = np.vstack((Train_corpus_data_features_count_nd,Test_corpus_data_features_count_nd))\n",
    "    #print(Combined_Matrix_01.shape)\n",
    "    #步驟8.把Combined_Matrix_01放入 Singular Value Decomposition函數中進行降維得到一個低維度的矩陣命名為「SVDed_Matrix_02」\n",
    "    #============去除SVD============#Combined_Matrix_01 = svd.fit_transform(Combined_Matrix_01)\n",
    "    #print(Combined_Matrix_01.shape)\n",
    "    #步驟9.將SVDed_Matrix_02矩陣的Train範圍 與 Test範圍 再次切開\n",
    "    #即矩陣的第0列到第399列為Train 命名為「Train_SVDed」\n",
    "    #矩陣的第400列到第499列為Test 命名為「Test_SVDed」\n",
    "    #============去除SVD============#Train_SVDed = Combined_Matrix_01[0:400,:]\n",
    "    #============去除SVD============#Test_SVDed = Combined_Matrix_01[400:500,:]\n",
    "    #print(Train_SVDed.shape)\n",
    "    #print(Test_SVDed.shape)\n",
    "    #步驟10.將Train_SVDed與相對應的Polarity Label送入Support Vector Machine 進行訓練得到模型\n",
    "    Train_svc_model = svm.SVC(kernel='rbf', C=C,cache_size=2048).fit(X=Train_corpus_data_features_count_nd, y=Train_Booking_review_Polarity)\n",
    "    #步驟11.將Test_SVDed送入訓練好的Support Vector Machine 模型取得預測結果\n",
    "    Test_svc_predict = Train_svc_model.predict(Test_corpus_data_features_count_nd)\n",
    "    #print(Test_svc_predict.shape)\n",
    "    #步驟12.比對預測結果與正確答案計算出Accuracy值\n",
    "    Hit = 0\n",
    "    Miss = 0\n",
    "    for index_number in range(len(Test_svc_predict)):\n",
    "        if Test_svc_predict[index_number] == Test_Booking_review_Polarity[index_number]:\n",
    "            Hit += 1\n",
    "        else:\n",
    "            Miss += 1\n",
    "    No_Word2Vec_Acc = Accuracy_set_value(Hit,Miss)\n",
    "    average_accuracy += No_Word2Vec_Acc\n",
    "    print()\n",
    "    print(\"迭代第 \",Routine,\" 次 未使用Word2Vec擴大的 Accuracy = \",No_Word2Vec_Acc*100,\"%\")\n",
    "    #實驗二 使用Train資料集訓練Word2Vec Test用Word2Vec擴大然後測試。\n",
    "    #步驟0.讀入Train資料集 400筆\n",
    "    Train_Booking_review = pd.read_csv(\"Booking_com_train_400筆.csv\",sep=',',names=[\"Polarity\",\"Context\"])\n",
    "    Train_Booking_review_Context = Train_Booking_review.Context\n",
    "    Train_Booking_review_Polarity = Train_Booking_review.Polarity\n",
    "    train_data_df_list = Train_Booking_review_Context.fillna(method=\"ffill\")\n",
    "    #步驟1.將Train送入Word2Vec函數進行訓練得到Word2Vec模型稱為Word2Vec()。\n",
    "    #步驟2.Train資料集 400筆 使用CountVectorizer 轉換為Bag of Word\n",
    "    Train_corpus_data_features_count = vectorizer_count.fit_transform(train_data_df_list)\n",
    "    Train_corpus_data_features_count_nd = Train_corpus_data_features_count.toarray()\n",
    "    #print(Train_corpus_data_features_count_nd.shape)\n",
    "    #步驟3.提取出Train的Feature Word特徵詞串列List\n",
    "    #Train_feature_list = vectorizer_count.get_feature_names()\n",
    "    #print(Train_feature_list)\n",
    "    #步驟4.讀入test資料集 100筆\n",
    "    Test_Booking_review = pd.read_csv(\"Booking_com_test_100筆.csv\",sep=',',names=[\"Polarity\",\"Context\"])\n",
    "    Test_Booking_review_Context = Test_Booking_review.Context\n",
    "    Test_Booking_review_Polarity = Test_Booking_review.Polarity\n",
    "    Test_data_df_list = Test_Booking_review_Context.fillna(method=\"ffill\")\n",
    "    #print(Test_data_df_list)\n",
    "    #步驟5.把Test的資料集送入Word2Vec()模型進行擴大，得到的新資料集命名為 Test_Word2Veced\n",
    "    train_data_df_list = []\n",
    "    #print(\"progress\",end=\"\")\n",
    "    for to_extend in Test_data_df_list.tolist():\n",
    "        try:\n",
    "            train_data_df_list.append(\" \".join(word2vec_extend(to_extend)))\n",
    "            #print(\".\",end=\"\")\n",
    "        except KeyError:\n",
    "            #print(\"*\",end=\"\")\n",
    "            train_data_df_list.append(to_extend)\n",
    "            pass\n",
    "        except TypeError:\n",
    "            #print(\"*\",end=\"\")\n",
    "            train_data_df_list.append(to_extend)\n",
    "            pass\n",
    "    #print(\"Done ...\")\n",
    "    #步驟6.把Test_Word2Veced的資料集中的每一筆評論依序提取出來\n",
    "    #步驟7.使用迭代的方式比對每一筆評論中的單字是否存在於Feature Word特徵詞串列List中\n",
    "    #如果存在者就按照原本的次數進行累加，原本不存在者就從1次開始累加。\n",
    "    #如果不在Feature Word特徵詞串列List的詞彙就丟棄\n",
    "    #(意思就是，重複出現在辭彙保留，原本沒有的字因為經由擴大才出現的辭彙則加入Feature Matrix)\n",
    "    #步驟8.以一則評論一個串列產生出Test_Word2Veced的特徵詞串列-矩陣\n",
    "    Test_corpus_data_features_count = vectorizer_count.transform(train_data_df_list)\n",
    "    Test_corpus_data_features_count_nd = Test_corpus_data_features_count.toarray()\n",
    "    #print(Test_corpus_data_features_count_nd.shape)\n",
    "    #步驟9.把 Train 與 Test_Word2Veced 矩陣合併 意即 Train 矩陣 後面串接 Test 矩陣合併後的矩陣命名為 「Combined_Matrix_01」\n",
    "    #Combined_Matrix_01 = np.vstack((Train_corpus_data_features_count_nd,Test_corpus_data_features_count_nd))\n",
    "    #print(Combined_Matrix_01.shape)\n",
    "    #步驟10.把Combined_Matrix_01放入 Singular Value Decomposition函數中進行降維得到一個低維度的矩陣命名為「SVDed_Matrix_02」\n",
    "    #============去除SVD============#Combined_Matrix_01 = svd.fit_transform(Combined_Matrix_01)\n",
    "    #print(Combined_Matrix_01.shape)\n",
    "    #步驟11.將SVDed_Matrix_02矩陣的Train範圍 與 Test範圍 再次切開\n",
    "    #即矩陣的第0列到第399列為Train 命名為「Train_SVDed」\n",
    "    #矩陣的第400列到第499列為Test 命名為「Test_Word2Veced_SVDed」\n",
    "    #============去除SVD============#Train_SVDed = Combined_Matrix_01[0:400,:]\n",
    "    #============去除SVD============#Test_Word2Veced_SVDed = Combined_Matrix_01[400:500,:]\n",
    "    #print(Train_SVDed.shape)\n",
    "    #print(Test_Word2Veced_SVDed.shape)\n",
    "    #步驟12.將Train_SVDed與相對應的Polarity Label送入Support Vector Machine 進行訓練得到模型\n",
    "    Train_svc_model = svm.SVC(kernel='rbf', C=C,cache_size=2048).fit(X=Train_corpus_data_features_count_nd, y=Train_Booking_review_Polarity)\n",
    "    #步驟13.將Test_SVDed送入訓練好的Support Vector Machine 模型取得預測結果\n",
    "    Test_svc_predict = Train_svc_model.predict(Test_corpus_data_features_count_nd)\n",
    "    #print(Test_svc_predict.shape)\n",
    "    #步驟14.比對預測結果與正確答案計算出Accuracy值\n",
    "    Hit = 0\n",
    "    Miss = 0\n",
    "    for index_number in range(len(Test_svc_predict)):\n",
    "        if Test_svc_predict[index_number] == Test_Booking_review_Polarity[index_number]:  #錯誤在這  原本寫成Train_Booking_review_Polarity\n",
    "            Hit += 1\n",
    "        else:\n",
    "            Miss += 1\n",
    "    Yes_Word2Vec_Acc = Accuracy_set_value(Hit,Miss)\n",
    "    word2vec_average_accuracy += Yes_Word2Vec_Acc\n",
    "    print(\"迭代第 \",Routine,\" 次  有使用Word2Vec擴大的 Accuracy = \",Yes_Word2Vec_Acc*100,\"%\")\n",
    "print()\n",
    "print(\"未使用Word2Vec擴大的平均 Accuracy =\",((average_accuracy)/counter)*100,\"%\")    \n",
    "print(\"有使用Word2Vec擴大的平均 Accuracy =\",((word2vec_average_accuracy)/counter)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Booking_com_train_訓練Word2Vec語料.txt file1 converted,OK!!\n",
      "Traning model is complete!!\n",
      "\n",
      "\n",
      "迭代第  1  次 未使用Word2Vec擴大的 Accuracy =  82.0 %\n",
      "迭代第  1  次  有使用Word2Vec擴大的 Accuracy =  80.0 %\n",
      "\n",
      "迭代第  2  次 未使用Word2Vec擴大的 Accuracy =  82.0 %\n",
      "迭代第  2  次  有使用Word2Vec擴大的 Accuracy =  80.0 %\n",
      "\n",
      "迭代第  3  次 未使用Word2Vec擴大的 Accuracy =  82.0 %\n",
      "迭代第  3  次  有使用Word2Vec擴大的 Accuracy =  80.0 %\n",
      "\n",
      "迭代第  4  次 未使用Word2Vec擴大的 Accuracy =  82.0 %\n",
      "迭代第  4  次  有使用Word2Vec擴大的 Accuracy =  80.0 %\n",
      "\n",
      "迭代第  5  次 未使用Word2Vec擴大的 Accuracy =  82.0 %\n",
      "迭代第  5  次  有使用Word2Vec擴大的 Accuracy =  80.0 %\n",
      "\n",
      "未使用Word2Vec擴大的平均 Accuracy = 82.0 %\n",
      "有使用Word2Vec擴大的平均 Accuracy = 80.0 %\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import os\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from string import punctuation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import libsvm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import grid_search\n",
    "\n",
    "\n",
    "parameters ={'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}\n",
    "#C = 10  #懲罰常數\n",
    "component = 1000  #降維維度\n",
    "most_simlr = 10  #擴展詞彙\n",
    "max_fea = 2000 #特徵數量\n",
    "vectorizer_count = CountVectorizer(analyzer='word',stop_words='english', encoding='utf-8',lowercase=True,max_features=max_fea)\n",
    "svd = TruncatedSVD(n_components=component)\n",
    "\n",
    "average_accuracy = 0\n",
    "word2vec_average_accuracy = 0\n",
    "\n",
    "#counter = int(input(\"請在此輸入要迭代的次數 : \"))\n",
    "counter = 5\n",
    "def Accuracy_set_value(hit,miss):\n",
    "    Accuracy = hit/(hit+miss)\n",
    "    return Accuracy\n",
    "#分析的評論句子用的前處理函數，會對輸入的句子去除標點符號，數字，非ascii字符，文字詞幹，轉換為寫小字母。\n",
    "def sentence_preprocess(sentence):\n",
    "    global punctuation\n",
    "    punctuation += \",\"+\"'\"+\".\"+\"&\"+\"!\"+\";\"+\":\"+\"...\"+\"´\"+\",\"\n",
    "    ascii_list = string.ascii_letters+\" \"\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    sentence = sentence.lower()\n",
    "    sentence = list(sentence)\n",
    "    out_sentence = \"\".join(stemmer.stem(c) for c in sentence if c not in punctuation)\n",
    "    out_sentence= \"\".join([i for i in out_sentence if not i.isdigit()])\n",
    "    out_sentence= \"\".join([i for i in out_sentence if i in ascii_list])\n",
    "    out_sentence = \" \".join(out_sentence.split())\n",
    "    out_sentence2 = [stemmer.stem(plural) for plural in out_sentence.split()]\n",
    "    out_sentence2 = \" \".join(out_sentence2)\n",
    "    if out_sentence2 == \"\":\n",
    "        out_sentence2 = \" The quick brown fox jumps over the lazy dog\"\n",
    "    out_sentence2 = out_sentence2.split()\n",
    "    return out_sentence2  #回傳值是List型態\n",
    "#Word2Vec使用的訓練語料庫必須為文字句子陣列，不須去詞幹，不須轉換大小寫。\n",
    "def word2vec_train():\n",
    "    global Word2Vec_Hotel_Traning_Model\n",
    "    training_list = []\n",
    "    with codecs.open(\"Booking_com_train_訓練Word2Vec語料.txt\",encoding=\"utf-8\", errors=\"backslashreplace\") as sourceFile1:         \n",
    "        training_file1 = sourceFile1.readlines()\n",
    "        for document_1 in training_file1:\n",
    "            training_list.append(document_1.split(\" \"))\n",
    "        print(\"Booking_com_train_訓練Word2Vec語料.txt file1 converted,OK!!\")\n",
    "    Word2Vec_Hotel_Traning_Model = Word2Vec(training_list)\n",
    "    print(\"Traning model is complete!!\")\n",
    "    print()\n",
    "word2vec_train()\n",
    "#接收的是一個句子的List  例如 [then,you,can,debug,the,threshold,with,generated ,tsv]\n",
    "#用於把原本的句子按照Word2Vec相關性擴展成更大的句子清單\n",
    "#基本上，一個原本有10個單字的句子，會被擴展成210個單字的句子\n",
    "#擴展過後的200個單字會加進原本10個單字句子的後面。\n",
    "#擴展的規則是，不去除重複的詞彙。\n",
    "def word2vec_extend(sentence_word_list):\n",
    "    if  type(sentence_word_list) == str:\n",
    "        sentence_word_list = sentence_word_list.split()\n",
    "    temp_list = []  #用於暫時存放擴展回傳的List\n",
    "    for word_text in sentence_word_list:\n",
    "        to_extend_word_list = Word2Vec_Hotel_Traning_Model.most_similar(word_text, topn=most_simlr)\n",
    "        temp_sentence = \"\"\n",
    "        for i in range(len(to_extend_word_list)):\n",
    "            temp_sentence += to_extend_word_list[i][0]+\" \"\n",
    "        temp_sentence = temp_sentence.split()\n",
    "        temp_list += temp_sentence\n",
    "    sentence_word_list += temp_list\n",
    "    return sentence_word_list   #把擴展後的110單字句子List回傳\n",
    "for Routine in range(counter):\n",
    "    Routine +=1\n",
    "    #實驗一 原本的評論語句不使用Word2Vec擴展\n",
    "    #步驟0.讀入Train資料集 400筆\n",
    "    Train_Booking_review = pd.read_csv(\"Booking_com_train_400筆.csv\",sep=',',names=[\"Polarity\",\"Context\"])\n",
    "    Train_Booking_review_Context = Train_Booking_review.Context\n",
    "    Train_Booking_review_Polarity = Train_Booking_review.Polarity\n",
    "    train_data_df_list = Train_Booking_review_Context.fillna(method=\"ffill\")\n",
    "    #步驟1.Train資料集 400筆 使用CountVectorizer 轉換為Bag of Word\n",
    "    Train_corpus_data_features_count = vectorizer_count.fit_transform(train_data_df_list)\n",
    "    Train_corpus_data_features_count_nd = Train_corpus_data_features_count.toarray()\n",
    "    #Train_corpus_data_features_count_nd.shape\n",
    "    #步驟2.提取出Train的Feature Word特徵詞串列List\n",
    "    #Train_feature_list = vectorizer_count.get_feature_names()\n",
    "    #print(Train_feature_list)\n",
    "    #步驟3.讀入test資料集 100筆\n",
    "    Test_Booking_review = pd.read_csv(\"Booking_com_test_100筆.csv\",sep=',',names=[\"Polarity\",\"Context\"])\n",
    "    Test_Booking_review_Context = Test_Booking_review.Context\n",
    "    Test_Booking_review_Polarity = Test_Booking_review.Polarity\n",
    "    Test_data_df_list = Test_Booking_review_Context.fillna(method=\"ffill\")\n",
    "    #print(Test_data_df_list)\n",
    "    #步驟4.把test的資料集中的每一筆評論依序提取出來\n",
    "    #步驟5.使用迭代的方式比對每一筆評論中的單字是否存在於Feature Word特徵詞串列List中\n",
    "    #步驟6.以一則評論一個串列產生出Test的特徵詞串列-矩陣\n",
    "    Test_corpus_data_features_count = vectorizer_count.transform(Test_data_df_list)\n",
    "    Test_corpus_data_features_count_nd = Test_corpus_data_features_count.toarray()\n",
    "    #Test_corpus_data_features_count_nd.shape\n",
    "    #步驟7.把Train 與 Test 矩陣合併 意即 Train矩陣 後面串接 Test矩陣\n",
    "    #合併後的矩陣命名為 「Combined_Matrix_01」\n",
    "    #============去除SVD============#Combined_Matrix_01 = np.vstack((Train_corpus_data_features_count_nd,Test_corpus_data_features_count_nd))\n",
    "    #print(Combined_Matrix_01.shape)\n",
    "    #步驟8.把Combined_Matrix_01放入 Singular Value Decomposition函數中進行降維得到一個低維度的矩陣命名為「SVDed_Matrix_02」\n",
    "    #============去除SVD============#Combined_Matrix_01 = svd.fit_transform(Combined_Matrix_01)\n",
    "    #print(Combined_Matrix_01.shape)\n",
    "    #步驟9.將SVDed_Matrix_02矩陣的Train範圍 與 Test範圍 再次切開\n",
    "    #即矩陣的第0列到第399列為Train 命名為「Train_SVDed」\n",
    "    #矩陣的第400列到第499列為Test 命名為「Test_SVDed」\n",
    "    #============去除SVD============#Train_SVDed = Combined_Matrix_01[0:400,:]\n",
    "    #============去除SVD============#Test_SVDed = Combined_Matrix_01[400:500,:]\n",
    "    #print(Train_SVDed.shape)\n",
    "    #print(Test_SVDed.shape)\n",
    "    #步驟10.將Train_SVDed與相對應的Polarity Label送入Support Vector Machine 進行訓練得到模型\n",
    "    Train_svc_model = grid_search.GridSearchCV(SVC(kernel='rbf',cache_size=2048), parameters).fit(X=Train_corpus_data_features_count_nd, y=Train_Booking_review_Polarity)\n",
    "    #步驟11.將Test_SVDed送入訓練好的Support Vector Machine 模型取得預測結果\n",
    "    Test_svc_predict = Train_svc_model.predict(Test_corpus_data_features_count_nd)\n",
    "    #print(Test_svc_predict.shape)\n",
    "    #步驟12.比對預測結果與正確答案計算出Accuracy值\n",
    "    Hit = 0\n",
    "    Miss = 0\n",
    "    for index_number in range(len(Test_svc_predict)):\n",
    "        if Test_svc_predict[index_number] == Test_Booking_review_Polarity[index_number]:\n",
    "            Hit += 1\n",
    "        else:\n",
    "            Miss += 1\n",
    "    No_Word2Vec_Acc = Accuracy_set_value(Hit,Miss)\n",
    "    average_accuracy += No_Word2Vec_Acc\n",
    "    print()\n",
    "    print(\"迭代第 \",Routine,\" 次 未使用Word2Vec擴大的 Accuracy = \",No_Word2Vec_Acc*100,\"%\")\n",
    "    #實驗二 使用Train資料集訓練Word2Vec Test用Word2Vec擴大然後測試。\n",
    "    #步驟0.讀入Train資料集 400筆\n",
    "    Train_Booking_review = pd.read_csv(\"Booking_com_train_400筆.csv\",sep=',',names=[\"Polarity\",\"Context\"])\n",
    "    Train_Booking_review_Context = Train_Booking_review.Context\n",
    "    Train_Booking_review_Polarity = Train_Booking_review.Polarity\n",
    "    train_data_df_list = Train_Booking_review_Context.fillna(method=\"ffill\")\n",
    "    #步驟1.將Train送入Word2Vec函數進行訓練得到Word2Vec模型稱為Word2Vec()。\n",
    "    #步驟2.Train資料集 400筆 使用CountVectorizer 轉換為Bag of Word\n",
    "    Train_corpus_data_features_count = vectorizer_count.fit_transform(train_data_df_list)\n",
    "    Train_corpus_data_features_count_nd = Train_corpus_data_features_count.toarray()\n",
    "    #print(Train_corpus_data_features_count_nd.shape)\n",
    "    #步驟3.提取出Train的Feature Word特徵詞串列List\n",
    "    #Train_feature_list = vectorizer_count.get_feature_names()\n",
    "    #print(Train_feature_list)\n",
    "    #步驟4.讀入test資料集 100筆\n",
    "    Test_Booking_review = pd.read_csv(\"Booking_com_test_100筆.csv\",sep=',',names=[\"Polarity\",\"Context\"])\n",
    "    Test_Booking_review_Context = Test_Booking_review.Context\n",
    "    Test_Booking_review_Polarity = Test_Booking_review.Polarity\n",
    "    Test_data_df_list = Test_Booking_review_Context.fillna(method=\"ffill\")\n",
    "    #print(Test_data_df_list)\n",
    "    #步驟5.把Test的資料集送入Word2Vec()模型進行擴大，得到的新資料集命名為 Test_Word2Veced\n",
    "    train_data_df_list = []\n",
    "    #print(\"progress\",end=\"\")\n",
    "    for to_extend in Test_data_df_list.tolist():\n",
    "        try:\n",
    "            train_data_df_list.append(\" \".join(word2vec_extend(to_extend)))\n",
    "            #print(\".\",end=\"\")\n",
    "        except KeyError:\n",
    "            #print(\"*\",end=\"\")\n",
    "            train_data_df_list.append(to_extend)\n",
    "            pass\n",
    "        except TypeError:\n",
    "            #print(\"*\",end=\"\")\n",
    "            train_data_df_list.append(to_extend)\n",
    "            pass\n",
    "    #print(\"Done ...\")\n",
    "    #步驟6.把Test_Word2Veced的資料集中的每一筆評論依序提取出來\n",
    "    #步驟7.使用迭代的方式比對每一筆評論中的單字是否存在於Feature Word特徵詞串列List中\n",
    "    #如果存在者就按照原本的次數進行累加，原本不存在者就從1次開始累加。\n",
    "    #如果不在Feature Word特徵詞串列List的詞彙就丟棄\n",
    "    #(意思就是，重複出現在辭彙保留，原本沒有的字因為經由擴大才出現的辭彙則加入Feature Matrix)\n",
    "    #步驟8.以一則評論一個串列產生出Test_Word2Veced的特徵詞串列-矩陣\n",
    "    Test_corpus_data_features_count = vectorizer_count.transform(train_data_df_list)\n",
    "    Test_corpus_data_features_count_nd = Test_corpus_data_features_count.toarray()\n",
    "    #print(Test_corpus_data_features_count_nd.shape)\n",
    "    #步驟9.把 Train 與 Test_Word2Veced 矩陣合併 意即 Train 矩陣 後面串接 Test 矩陣合併後的矩陣命名為 「Combined_Matrix_01」\n",
    "    #Combined_Matrix_01 = np.vstack((Train_corpus_data_features_count_nd,Test_corpus_data_features_count_nd))\n",
    "    #print(Combined_Matrix_01.shape)\n",
    "    #步驟10.把Combined_Matrix_01放入 Singular Value Decomposition函數中進行降維得到一個低維度的矩陣命名為「SVDed_Matrix_02」\n",
    "    #============去除SVD============#Combined_Matrix_01 = svd.fit_transform(Combined_Matrix_01)\n",
    "    #print(Combined_Matrix_01.shape)\n",
    "    #步驟11.將SVDed_Matrix_02矩陣的Train範圍 與 Test範圍 再次切開\n",
    "    #即矩陣的第0列到第399列為Train 命名為「Train_SVDed」\n",
    "    #矩陣的第400列到第499列為Test 命名為「Test_Word2Veced_SVDed」\n",
    "    #============去除SVD============#Train_SVDed = Combined_Matrix_01[0:400,:]\n",
    "    #============去除SVD============#Test_Word2Veced_SVDed = Combined_Matrix_01[400:500,:]\n",
    "    #print(Train_SVDed.shape)\n",
    "    #print(Test_Word2Veced_SVDed.shape)\n",
    "    #步驟12.將Train_SVDed與相對應的Polarity Label送入Support Vector Machine 進行訓練得到模型\n",
    "    Train_svc_model = grid_search.GridSearchCV(SVC(kernel='rbf',cache_size=2048), parameters).fit(X=Train_corpus_data_features_count_nd, y=Train_Booking_review_Polarity)\n",
    "    #步驟13.將Test_SVDed送入訓練好的Support Vector Machine 模型取得預測結果\n",
    "    Test_svc_predict = Train_svc_model.predict(Test_corpus_data_features_count_nd)\n",
    "    #print(Test_svc_predict.shape)\n",
    "    #步驟14.比對預測結果與正確答案計算出Accuracy值\n",
    "    Hit = 0\n",
    "    Miss = 0\n",
    "    for index_number in range(len(Test_svc_predict)):\n",
    "        if Test_svc_predict[index_number] == Test_Booking_review_Polarity[index_number]:  #錯誤在這  原本寫成Train_Booking_review_Polarity\n",
    "            Hit += 1\n",
    "        else:\n",
    "            Miss += 1\n",
    "    Yes_Word2Vec_Acc = Accuracy_set_value(Hit,Miss)\n",
    "    word2vec_average_accuracy += Yes_Word2Vec_Acc\n",
    "    print(\"迭代第 \",Routine,\" 次  有使用Word2Vec擴大的 Accuracy = \",Yes_Word2Vec_Acc*100,\"%\")\n",
    "print()\n",
    "print(\"未使用Word2Vec擴大的平均 Accuracy =\",((average_accuracy)/counter)*100,\"%\")    \n",
    "print(\"有使用Word2Vec擴大的平均 Accuracy =\",((word2vec_average_accuracy)/counter)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
